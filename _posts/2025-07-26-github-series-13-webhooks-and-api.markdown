---
layout: post
title: "[GitHub ì…ë¬¸ #13] Webhooksì™€ API: ì™¸ë¶€ ì„œë¹„ìŠ¤ ì—°ë™"
date: 2025-07-26 10:00:00 +0900
categories: [DevOps, GitHub]
tags: [github, webhooks, api, integration, automation, tutorial, series]
mermaid: true
---

## ë“¤ì–´ê°€ë©°

GitHub ì…ë¬¸ ì‹œë¦¬ì¦ˆì˜ ì—´ì„¸ ë²ˆì§¸ ì‹œê°„ì…ë‹ˆë‹¤. ì´ë²ˆì—ëŠ” GitHub Webhooksì™€ APIë¥¼ í™œìš©í•˜ì—¬ ì™¸ë¶€ ì„œë¹„ìŠ¤ì™€ ì—°ë™í•˜ëŠ” ë°©ë²•ì„ ì•Œì•„ë³´ê² ìŠµë‹ˆë‹¤. ì´ë¥¼ í†µí•´ GitHub ì´ë²¤íŠ¸ë¥¼ ì‹¤ì‹œê°„ìœ¼ë¡œ ì²˜ë¦¬í•˜ê³  ìë™í™”ë¥¼ êµ¬í˜„í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

## Webhooksì™€ API ê°œìš”

### ì£¼ìš” ì°¨ì´ì 

| êµ¬ë¶„ | Webhooks | API |
|------|----------|-----|
| **í†µì‹  ë°©ì‹** | Push (GitHub â†’ ì„œë²„) | Pull (ì„œë²„ â†’ GitHub) |
| **ì‹¤ì‹œê°„ì„±** | ì¦‰ì‹œ ì•Œë¦¼ | í´ë§ í•„ìš” |
| **ìš©ë„** | ì´ë²¤íŠ¸ ê¸°ë°˜ ìë™í™” | ë°ì´í„° ì¡°íšŒ/ì¡°ì‘ |
| **ì¸ì¦** | Secret í† í° | OAuth/PAT |
| **ì œí•œ** | ì´ë²¤íŠ¸ íƒ€ì…ë³„ | Rate Limit |

## 1. GitHub Webhooks ì´í•´í•˜ê¸°

WebhooksëŠ” GitHubì—ì„œ íŠ¹ì • ì´ë²¤íŠ¸ê°€ ë°œìƒí–ˆì„ ë•Œ ì™¸ë¶€ ì„œë²„ë¡œ HTTP POST ìš”ì²­ì„ ë³´ë‚´ëŠ” ê¸°ëŠ¥ì…ë‹ˆë‹¤.

### Webhook ë™ì‘ ì›ë¦¬

```
GitHub Repository          Your Server
      |                         |
      | Event occurs           |
      |----------------------->|
      | POST /webhook          |
      | {event data}          |
      |                        |
      |<----------------------|
      | 200 OK                |
```

### ì£¼ìš” Webhook ì´ë²¤íŠ¸

```mermaid
graph TD
    A[GitHub Events] --> B[Repository]
    A --> C[Pull Request]
    A --> D[Issues]
    A --> E[Actions]
    
    B --> B1[push]
    B --> B2[create/delete]
    B --> B3[release]
    
    C --> C1[opened/closed]
    C --> C2[review]
    C --> C3[merged]
    
    D --> D1[opened/closed]
    D --> D2[comment]
    D --> D3[labeled]
    
    E --> E1[workflow_run]
    E --> E2[deployment]
```

### Webhook ì´ë²¤íŠ¸ ìƒì„¸ ëª©ë¡

| ì¹´í…Œê³ ë¦¬ | ì´ë²¤íŠ¸ | ì„¤ëª… | ì£¼ìš” ìš©ë„ |
|----------|--------|------|-----------|
| **Repository** | push | ì½”ë“œ í‘¸ì‹œ | CI/CD íŠ¸ë¦¬ê±° |
| | create | ë¸Œëœì¹˜/íƒœê·¸ ìƒì„± | ìë™ ë¸Œëœì¹˜ ë³´í˜¸ |
| | release | ë¦´ë¦¬ì¦ˆ ë°œí–‰ | ë°°í¬ ìë™í™” |
| **Pull Request** | pull_request | PR ìƒíƒœ ë³€ê²½ | ì½”ë“œ ë¦¬ë·° ë´‡ |
| | pull_request_review | ë¦¬ë·° ì œì¶œ | ìŠ¹ì¸ í”„ë¡œì„¸ìŠ¤ |
| **Issues** | issues | ì´ìŠˆ ìƒíƒœ ë³€ê²½ | ì´ìŠˆ íŠ¸ë˜í‚¹ |
| | issue_comment | ì½”ë©˜íŠ¸ ì¶”ê°€ | ìë™ ì‘ë‹µ |
| **Actions** | workflow_run | ì›Œí¬í”Œë¡œìš° ì™„ë£Œ | ìƒíƒœ ëª¨ë‹ˆí„°ë§ |
| | deployment_status | ë°°í¬ ìƒíƒœ | ë°°í¬ ì•Œë¦¼ |

## 2. Webhook ì„œë²„ êµ¬í˜„

### Node.js Express ì„œë²„

```javascript
// webhook-server.js
const express = require('express');
const crypto = require('crypto');
const { Octokit } = require('@octokit/rest');

const app = express();
const PORT = process.env.PORT || 3000;
const WEBHOOK_SECRET = process.env.WEBHOOK_SECRET;
const GITHUB_TOKEN = process.env.GITHUB_TOKEN;

const octokit = new Octokit({ auth: GITHUB_TOKEN });

// Raw bodyë¥¼ ìœ„í•œ ë¯¸ë“¤ì›¨ì–´
app.use(express.json({
  verify: (req, res, buf, encoding) => {
    req.rawBody = buf.toString(encoding || 'utf8');
  }
}));

// Webhook ì„œëª… ê²€ì¦
function verifyWebhookSignature(req) {
  const signature = req.headers['x-hub-signature-256'];
  if (!signature) return false;

  const hmac = crypto.createHmac('sha256', WEBHOOK_SECRET);
  const digest = 'sha256=' + hmac.update(req.rawBody).digest('hex');
  
  return crypto.timingSafeEqual(
    Buffer.from(signature),
    Buffer.from(digest)
  );
}

// Webhook ì—”ë“œí¬ì¸íŠ¸
app.post('/webhook', async (req, res) => {
  // ì„œëª… ê²€ì¦
  if (!verifyWebhookSignature(req)) {
    return res.status(401).send('Unauthorized');
  }

  const event = req.headers['x-github-event'];
  const payload = req.body;

  console.log(`Received ${event} event`);

  try {
    // ì´ë²¤íŠ¸ë³„ ì²˜ë¦¬
    switch (event) {
      case 'push':
        await handlePushEvent(payload);
        break;
      case 'pull_request':
        await handlePullRequestEvent(payload);
        break;
      case 'issues':
        await handleIssueEvent(payload);
        break;
      case 'release':
        await handleReleaseEvent(payload);
        break;
      default:
        console.log(`Unhandled event type: ${event}`);
    }

    res.status(200).send('OK');
  } catch (error) {
    console.error('Error processing webhook:', error);
    res.status(500).send('Internal Server Error');
  }
});

// Push ì´ë²¤íŠ¸ ì²˜ë¦¬
async function handlePushEvent(payload) {
  const { repository, ref, commits, pusher } = payload;
  
  // main ë¸Œëœì¹˜ í‘¸ì‹œë§Œ ì²˜ë¦¬
  if (ref !== 'refs/heads/main') {
    return;
  }

  console.log(`Push to main by ${pusher.name}`);
  console.log(`${commits.length} commits pushed`);

  // ì»¤ë°‹ ë©”ì‹œì§€ ë¶„ì„
  for (const commit of commits) {
    if (commit.message.includes('[deploy]')) {
      console.log('Triggering deployment...');
      await triggerDeployment(repository, commit);
    }

    if (commit.message.includes('[notify]')) {
      await sendNotification(repository, commit);
    }
  }

  // ì½”ë“œ í’ˆì§ˆ ì²´í¬ íŠ¸ë¦¬ê±°
  await triggerCodeQualityCheck(repository, payload.after);
}

// Pull Request ì´ë²¤íŠ¸ ì²˜ë¦¬
async function handlePullRequestEvent(payload) {
  const { action, pull_request, repository } = payload;

  switch (action) {
    case 'opened':
      // ìë™ ë¼ë²¨ ì¶”ê°€
      await addLabelsBasedOnFiles(repository, pull_request);
      
      // ë¦¬ë·°ì–´ ìë™ í• ë‹¹
      await assignReviewers(repository, pull_request);
      
      // í™˜ì˜ ë©”ì‹œì§€
      if (pull_request.user.type === 'User' && isFirstTimeContributor(pull_request.user)) {
        await postWelcomeComment(repository, pull_request);
      }
      break;

    case 'synchronize':
      // PR ì—…ë°ì´íŠ¸ ì‹œ ì²´í¬ ì¬ì‹¤í–‰
      await runPRChecks(repository, pull_request);
      break;

    case 'closed':
      if (pull_request.merged) {
        // ë¨¸ì§€ í›„ ì²˜ë¦¬
        await handleMergedPR(repository, pull_request);
      }
      break;
  }
}

// íŒŒì¼ ë³€ê²½ ê¸°ë°˜ ë¼ë²¨ ì¶”ê°€
async function addLabelsBasedOnFiles(repository, pull_request) {
  const { data: files } = await octokit.pulls.listFiles({
    owner: repository.owner.login,
    repo: repository.name,
    pull_number: pull_request.number,
  });

  const labels = new Set();

  for (const file of files) {
    if (file.filename.startsWith('src/')) {
      labels.add('code');
    }
    if (file.filename.endsWith('.md')) {
      labels.add('documentation');
    }
    if (file.filename.includes('test')) {
      labels.add('tests');
    }
    if (file.filename.startsWith('.github/')) {
      labels.add('ci/cd');
    }
  }

  if (labels.size > 0) {
    await octokit.issues.addLabels({
      owner: repository.owner.login,
      repo: repository.name,
      issue_number: pull_request.number,
      labels: Array.from(labels),
    });
  }
}

// ë¦¬ë·°ì–´ ìë™ í• ë‹¹
async function assignReviewers(repository, pull_request) {
  // CODEOWNERS íŒŒì¼ ì½ê¸°
  try {
    const { data: codeowners } = await octokit.repos.getContent({
      owner: repository.owner.login,
      repo: repository.name,
      path: '.github/CODEOWNERS',
    });

    const content = Buffer.from(codeowners.content, 'base64').toString();
    const reviewers = parseCodeOwners(content, pull_request);

    if (reviewers.length > 0) {
      await octokit.pulls.requestReviewers({
        owner: repository.owner.login,
        repo: repository.name,
        pull_number: pull_request.number,
        reviewers: reviewers.filter(r => r !== pull_request.user.login),
      });
    }
  } catch (error) {
    console.log('No CODEOWNERS file found');
  }
}

// Issue ì´ë²¤íŠ¸ ì²˜ë¦¬
async function handleIssueEvent(payload) {
  const { action, issue, repository } = payload;

  if (action === 'opened') {
    // ì´ìŠˆ í…œí”Œë¦¿ í™•ì¸
    if (!issue.body || issue.body.trim().length < 50) {
      await octokit.issues.createComment({
        owner: repository.owner.login,
        repo: repository.name,
        issue_number: issue.number,
        body: 'ì´ìŠˆ ì„¤ëª…ì´ ë„ˆë¬´ ì§§ìŠµë‹ˆë‹¤. ë” ìì„¸í•œ ì •ë³´ë¥¼ ì œê³µí•´ì£¼ì„¸ìš”.',
      });
    }

    // ìë™ ë¶„ë¥˜
    await categorizeIssue(repository, issue);
  }
}

// Release ì´ë²¤íŠ¸ ì²˜ë¦¬
async function handleReleaseEvent(payload) {
  const { action, release, repository } = payload;

  if (action === 'published') {
    console.log(`New release: ${release.tag_name}`);

    // ë¦´ë¦¬ì¦ˆ ë…¸íŠ¸ ìƒì„±
    const releaseNotes = await generateReleaseNotes(repository, release);
    
    // ì™¸ë¶€ ì„œë¹„ìŠ¤ ì•Œë¦¼
    await notifyExternalServices(release, releaseNotes);
    
    // ë¬¸ì„œ ì—…ë°ì´íŠ¸ íŠ¸ë¦¬ê±°
    await triggerDocsUpdate(repository, release);
  }
}

app.listen(PORT, () => {
  console.log(`Webhook server listening on port ${PORT}`);
});
```

### Python Flask ì„œë²„

```python
# webhook_server.py
from flask import Flask, request, jsonify
import hmac
import hashlib
import json
import requests
from github import Github
import os

app = Flask(__name__)
WEBHOOK_SECRET = os.environ.get('WEBHOOK_SECRET', '').encode()
GITHUB_TOKEN = os.environ.get('GITHUB_TOKEN')

g = Github(GITHUB_TOKEN)

def verify_webhook_signature(data, signature):
    """Webhook ì„œëª… ê²€ì¦"""
    if not signature:
        return False
    
    sha_name, signature = signature.split('=')
    if sha_name != 'sha256':
        return False
    
    mac = hmac.new(WEBHOOK_SECRET, msg=data, digestmod=hashlib.sha256)
    return hmac.compare_digest(mac.hexdigest(), signature)

@app.route('/webhook', methods=['POST'])
def github_webhook():
    # ì„œëª… ê²€ì¦
    signature = request.headers.get('X-Hub-Signature-256')
    if not verify_webhook_signature(request.data, signature):
        return jsonify({'error': 'Invalid signature'}), 401
    
    event = request.headers.get('X-GitHub-Event')
    payload = request.json
    
    # ì´ë²¤íŠ¸ë³„ ì²˜ë¦¬
    handlers = {
        'push': handle_push,
        'pull_request': handle_pull_request,
        'issues': handle_issues,
        'workflow_run': handle_workflow_run,
        'deployment_status': handle_deployment_status,
    }
    
    handler = handlers.get(event)
    if handler:
        try:
            handler(payload)
            return jsonify({'status': 'success'}), 200
        except Exception as e:
            app.logger.error(f'Error handling {event}: {str(e)}')
            return jsonify({'error': str(e)}), 500
    else:
        app.logger.info(f'Unhandled event: {event}')
        return jsonify({'status': 'ignored'}), 200

def handle_push(payload):
    """Push ì´ë²¤íŠ¸ ì²˜ë¦¬"""
    repo_name = payload['repository']['full_name']
    branch = payload['ref'].split('/')[-1]
    commits = payload['commits']
    
    # íŠ¹ì • ë¸Œëœì¹˜ë§Œ ì²˜ë¦¬
    if branch not in ['main', 'master', 'develop']:
        return
    
    repo = g.get_repo(repo_name)
    
    # ì»¤ë°‹ ë¶„ì„
    for commit in commits:
        sha = commit['id']
        message = commit['message']
        
        # ì»¤ë°‹ ë©”ì‹œì§€ íŒ¨í„´ í™•ì¸
        if '[hotfix]' in message.lower():
            create_hotfix_issue(repo, commit)
        
        if '[breaking]' in message.lower():
            notify_breaking_change(repo, commit)
        
        # ë³´ì•ˆ í‚¤ì›Œë“œ í™•ì¸
        check_security_keywords(repo, commit)

def handle_pull_request(payload):
    """Pull Request ì´ë²¤íŠ¸ ì²˜ë¦¬"""
    action = payload['action']
    pr = payload['pull_request']
    repo_name = payload['repository']['full_name']
    
    repo = g.get_repo(repo_name)
    pull = repo.get_pull(pr['number'])
    
    if action == 'opened':
        # PR í¬ê¸° í™•ì¸
        if pr['additions'] + pr['deletions'] > 500:
            pull.create_issue_comment(
                "âš ï¸ ì´ PRì´ ë„ˆë¬´ í½ë‹ˆë‹¤ (500ì¤„ ì´ìƒ). "
                "ë” ì‘ì€ ë‹¨ìœ„ë¡œ ë‚˜ëˆ„ëŠ” ê²ƒì„ ê³ ë ¤í•´ì£¼ì„¸ìš”."
            )
        
        # ë¸Œëœì¹˜ ì´ë¦„ ê·œì¹™ í™•ì¸
        if not is_valid_branch_name(pr['head']['ref']):
            pull.create_issue_comment(
                "âŒ ë¸Œëœì¹˜ ì´ë¦„ì´ ê·œì¹™ì„ ë”°ë¥´ì§€ ì•ŠìŠµë‹ˆë‹¤.\n"
                "ì˜¬ë°”ë¥¸ í˜•ì‹: feature/*, bugfix/*, hotfix/*"
            )
        
        # ê´€ë ¨ ì´ìŠˆ í™•ì¸
        if not has_linked_issue(pr):
            pull.create_issue_comment(
                "ğŸ“ ê´€ë ¨ ì´ìŠˆë¥¼ ì—°ê²°í•´ì£¼ì„¸ìš”. "
                "PR ì„¤ëª…ì— 'Fixes #123' í˜•ì‹ì„ ì‚¬ìš©í•˜ì„¸ìš”."
            )
    
    elif action == 'synchronize':
        # ì¶©ëŒ í™•ì¸
        if not pull.mergeable:
            pull.create_issue_comment(
                "ğŸ”„ ë³‘í•© ì¶©ëŒì´ ë°œìƒí–ˆìŠµë‹ˆë‹¤. í•´ê²°í•´ì£¼ì„¸ìš”."
            )

def handle_workflow_run(payload):
    """GitHub Actions ì›Œí¬í”Œë¡œìš° ì‹¤í–‰ ê²°ê³¼ ì²˜ë¦¬"""
    workflow_run = payload['workflow_run']
    conclusion = workflow_run['conclusion']
    
    if conclusion == 'failure':
        # ì‹¤íŒ¨ ì•Œë¦¼
        send_notification({
            'type': 'workflow_failure',
            'workflow': workflow_run['name'],
            'run_id': workflow_run['id'],
            'url': workflow_run['html_url'],
            'repository': payload['repository']['full_name'],
        })
        
        # ìë™ ì´ìŠˆ ìƒì„±
        if workflow_run['name'] == 'Nightly Build':
            create_build_failure_issue(payload)

def create_build_failure_issue(payload):
    """ë¹Œë“œ ì‹¤íŒ¨ ì´ìŠˆ ìë™ ìƒì„±"""
    repo_name = payload['repository']['full_name']
    workflow_run = payload['workflow_run']
    
    repo = g.get_repo(repo_name)
    
    # ì¤‘ë³µ ì´ìŠˆ í™•ì¸
    existing_issues = repo.get_issues(
        state='open',
        labels=['build-failure', 'automated']
    )
    
    for issue in existing_issues:
        if f"Run ID: {workflow_run['id']}" in issue.body:
            return  # ì´ë¯¸ ì´ìŠˆê°€ ì¡´ì¬í•¨
    
    # ìƒˆ ì´ìŠˆ ìƒì„±
    issue = repo.create_issue(
        title=f"Build Failure: {workflow_run['name']}",
        body=f"""
## Build Failure Report

**Workflow**: {workflow_run['name']}
**Run ID**: {workflow_run['id']}
**Branch**: {workflow_run['head_branch']}
**Commit**: {workflow_run['head_sha'][:7]}
**Time**: {workflow_run['created_at']}

[View Workflow Run]({workflow_run['html_url']})

### Automated Issue
This issue was automatically created by the webhook handler.
        """,
        labels=['build-failure', 'automated', 'high-priority']
    )

if __name__ == '__main__':
    app.run(port=3000, debug=True)
```

## 3. GitHub API í™œìš©

### REST API ê¸°ë³¸ ì‚¬ìš©ë²•

```javascript
// github-api-client.js
const { Octokit } = require('@octokit/rest');
const { retry } = require('@octokit/plugin-retry');
const { throttling } = require('@octokit/plugin-throttling');

// í”ŒëŸ¬ê·¸ì¸ì´ ì ìš©ëœ Octokit ìƒì„±
const MyOctokit = Octokit.plugin(retry, throttling);

const octokit = new MyOctokit({
  auth: process.env.GITHUB_TOKEN,
  throttle: {
    onRateLimit: (retryAfter, options) => {
      console.warn(`Rate limit hit for ${options.method} ${options.url}`);
      if (options.request.retryCount === 0) {
        console.log(`Retrying after ${retryAfter} seconds!`);
        return true;
      }
    },
    onAbuseLimit: (retryAfter, options) => {
      console.warn(`Abuse limit hit for ${options.method} ${options.url}`);
    },
  },
});

// Repository ì •ë³´ ì¡°íšŒ
async function getRepositoryInfo(owner, repo) {
  try {
    const { data } = await octokit.repos.get({ owner, repo });
    return {
      name: data.name,
      description: data.description,
      stars: data.stargazers_count,
      forks: data.forks_count,
      language: data.language,
      topics: data.topics,
      created_at: data.created_at,
      updated_at: data.updated_at,
    };
  } catch (error) {
    console.error('Error fetching repository:', error.message);
    throw error;
  }
}

// ëª¨ë“  ì´ìŠˆ ê°€ì ¸ì˜¤ê¸° (í˜ì´ì§€ë„¤ì´ì…˜)
async function getAllIssues(owner, repo, state = 'all') {
  const issues = await octokit.paginate(octokit.issues.listForRepo, {
    owner,
    repo,
    state,
    per_page: 100,
  });
  
  return issues.filter(issue => !issue.pull_request);
}

// PR í†µê³„ ìƒì„±
async function generatePRStats(owner, repo, days = 30) {
  const since = new Date();
  since.setDate(since.getDate() - days);
  
  const pulls = await octokit.paginate(octokit.pulls.list, {
    owner,
    repo,
    state: 'all',
    sort: 'created',
    direction: 'desc',
    per_page: 100,
  });
  
  const recentPulls = pulls.filter(pr => 
    new Date(pr.created_at) > since
  );
  
  const stats = {
    total: recentPulls.length,
    open: recentPulls.filter(pr => pr.state === 'open').length,
    merged: recentPulls.filter(pr => pr.merged_at).length,
    avgTimeToMerge: 0,
    contributors: new Set(),
  };
  
  let totalMergeTime = 0;
  let mergedCount = 0;
  
  for (const pr of recentPulls) {
    stats.contributors.add(pr.user.login);
    
    if (pr.merged_at) {
      const created = new Date(pr.created_at);
      const merged = new Date(pr.merged_at);
      totalMergeTime += merged - created;
      mergedCount++;
    }
  }
  
  if (mergedCount > 0) {
    stats.avgTimeToMerge = totalMergeTime / mergedCount / (1000 * 60 * 60); // hours
  }
  
  stats.contributors = stats.contributors.size;
  
  return stats;
}

// ìë™í™”ëœ ë¦´ë¦¬ì¦ˆ ìƒì„±
async function createAutomatedRelease(owner, repo, tagName, options = {}) {
  // ìµœê·¼ ë¦´ë¦¬ì¦ˆ í™•ì¸
  const { data: latestRelease } = await octokit.repos.getLatestRelease({
    owner,
    repo,
  }).catch(() => ({ data: null }));
  
  // ë³€ê²½ì‚¬í•­ ìˆ˜ì§‘
  const compareBase = latestRelease ? latestRelease.tag_name : 'HEAD~20';
  const { data: comparison } = await octokit.repos.compareCommits({
    owner,
    repo,
    base: compareBase,
    head: 'HEAD',
  });
  
  // ë¦´ë¦¬ì¦ˆ ë…¸íŠ¸ ìƒì„±
  const releaseNotes = generateReleaseNotes(comparison.commits);
  
  // ë¦´ë¦¬ì¦ˆ ìƒì„±
  const { data: release } = await octokit.repos.createRelease({
    owner,
    repo,
    tag_name: tagName,
    name: options.name || tagName,
    body: releaseNotes,
    draft: options.draft || false,
    prerelease: options.prerelease || false,
    target_commitish: options.target || 'main',
  });
  
  return release;
}

function generateReleaseNotes(commits) {
  const notes = {
    features: [],
    fixes: [],
    others: [],
  };
  
  for (const commit of commits) {
    const message = commit.commit.message;
    const firstLine = message.split('\n')[0];
    
    if (firstLine.startsWith('feat:')) {
      notes.features.push(firstLine);
    } else if (firstLine.startsWith('fix:')) {
      notes.fixes.push(firstLine);
    } else {
      notes.others.push(firstLine);
    }
  }
  
  let releaseBody = '## What\'s Changed\n\n';
  
  if (notes.features.length > 0) {
    releaseBody += '### ğŸš€ New Features\n';
    notes.features.forEach(feat => {
      releaseBody += `- ${feat}\n`;
    });
    releaseBody += '\n';
  }
  
  if (notes.fixes.length > 0) {
    releaseBody += '### ğŸ› Bug Fixes\n';
    notes.fixes.forEach(fix => {
      releaseBody += `- ${fix}\n`;
    });
    releaseBody += '\n';
  }
  
  if (notes.others.length > 0) {
    releaseBody += '### ğŸ“ Other Changes\n';
    notes.others.forEach(other => {
      releaseBody += `- ${other}\n`;
    });
  }
  
  return releaseBody;
}

module.exports = {
  octokit,
  getRepositoryInfo,
  getAllIssues,
  generatePRStats,
  createAutomatedRelease,
};
```

### GraphQL API ì‚¬ìš©

```javascript
// github-graphql-client.js
const { graphql } = require('@octokit/graphql');

const graphqlWithAuth = graphql.defaults({
  headers: {
    authorization: `token ${process.env.GITHUB_TOKEN}`,
  },
});

// ë³µì¡í•œ ì¿¼ë¦¬ ì˜ˆì œ
async function getRepositoryDetails(owner, name) {
  const query = `
    query GetRepoDetails($owner: String!, $name: String!) {
      repository(owner: $owner, name: $name) {
        name
        description
        createdAt
        updatedAt
        primaryLanguage {
          name
          color
        }
        languages(first: 10) {
          edges {
            node {
              name
              color
            }
            size
          }
          totalSize
        }
        issues(states: OPEN) {
          totalCount
        }
        pullRequests(states: OPEN) {
          totalCount
        }
        stargazers {
          totalCount
        }
        forks {
          totalCount
        }
        releases(first: 5, orderBy: {field: CREATED_AT, direction: DESC}) {
          nodes {
            tagName
            createdAt
            author {
              login
            }
          }
        }
        collaborators(first: 10) {
          edges {
            node {
              login
              avatarUrl
            }
            permission
          }
        }
        defaultBranchRef {
          name
          target {
            ... on Commit {
              history(first: 1) {
                nodes {
                  message
                  committedDate
                  author {
                    name
                  }
                }
              }
            }
          }
        }
      }
    }
  `;
  
  try {
    const result = await graphqlWithAuth(query, { owner, name });
    return result.repository;
  } catch (error) {
    console.error('GraphQL query failed:', error.message);
    throw error;
  }
}

// ì‚¬ìš©ì ê¸°ì—¬ë„ ë¶„ì„
async function analyzeUserContributions(username, days = 365) {
  const since = new Date();
  since.setDate(since.getDate() - days);
  
  const query = `
    query GetUserContributions($username: String!, $since: DateTime!) {
      user(login: $username) {
        login
        name
        bio
        contributionsCollection(from: $since) {
          totalCommitContributions
          totalIssueContributions
          totalPullRequestContributions
          totalPullRequestReviewContributions
          contributionCalendar {
            totalContributions
            weeks {
              contributionDays {
                contributionCount
                date
                color
              }
            }
          }
          commitContributionsByRepository(maxRepositories: 10) {
            repository {
              name
              owner {
                login
              }
            }
            contributions {
              totalCount
            }
          }
        }
        repositories(first: 100, ownerAffiliations: OWNER) {
          totalCount
          nodes {
            name
            stargazers {
              totalCount
            }
          }
        }
        followers {
          totalCount
        }
        following {
          totalCount
        }
      }
    }
  `;
  
  const result = await graphqlWithAuth(query, {
    username,
    since: since.toISOString(),
  });
  
  return result.user;
}

// ì¡°ì§ ë¶„ì„
async function analyzeOrganization(orgName) {
  const query = `
    query AnalyzeOrg($orgName: String!) {
      organization(login: $orgName) {
        name
        description
        createdAt
        repositories(first: 100, privacy: PUBLIC) {
          totalCount
          nodes {
            name
            primaryLanguage {
              name
            }
            stargazers {
              totalCount
            }
            forks {
              totalCount
            }
            issues(states: OPEN) {
              totalCount
            }
          }
        }
        membersWithRole {
          totalCount
        }
        teams(first: 20) {
          totalCount
          nodes {
            name
            description
            members {
              totalCount
            }
          }
        }
      }
    }
  `;
  
  const result = await graphqlWithAuth(query, { orgName });
  
  // í†µê³„ ê³„ì‚°
  const stats = {
    totalRepos: result.organization.repositories.totalCount,
    totalStars: 0,
    totalForks: 0,
    totalOpenIssues: 0,
    languageDistribution: {},
    topRepos: [],
  };
  
  result.organization.repositories.nodes.forEach(repo => {
    stats.totalStars += repo.stargazers.totalCount;
    stats.totalForks += repo.forks.totalCount;
    stats.totalOpenIssues += repo.issues.totalCount;
    
    if (repo.primaryLanguage) {
      const lang = repo.primaryLanguage.name;
      stats.languageDistribution[lang] = (stats.languageDistribution[lang] || 0) + 1;
    }
  });
  
  stats.topRepos = result.organization.repositories.nodes
    .sort((a, b) => b.stargazers.totalCount - a.stargazers.totalCount)
    .slice(0, 5)
    .map(repo => ({
      name: repo.name,
      stars: repo.stargazers.totalCount,
    }));
  
  return {
    organization: result.organization,
    stats,
  };
}

module.exports = {
  graphqlWithAuth,
  getRepositoryDetails,
  analyzeUserContributions,
  analyzeOrganization,
};
```

## 4. Webhookê³¼ API í†µí•© ì˜ˆì œ

### ìë™ ì´ìŠˆ ê´€ë¦¬ ì‹œìŠ¤í…œ

```javascript
// issue-automation.js
const express = require('express');
const { Octokit } = require('@octokit/rest');
const natural = require('natural');

const app = express();
const octokit = new Octokit({ auth: process.env.GITHUB_TOKEN });

// NLP ë¶„ë¥˜ê¸° ì´ˆê¸°í™”
const classifier = new natural.BayesClassifier();

// í•™ìŠµ ë°ì´í„°
const trainingData = [
  { text: 'app crashes when clicking button', category: 'bug' },
  { text: 'add dark mode support', category: 'enhancement' },
  { text: 'update installation guide', category: 'documentation' },
  { text: 'improve performance of search', category: 'performance' },
  { text: 'security vulnerability in dependencies', category: 'security' },
];

trainingData.forEach(item => {
  classifier.addDocument(item.text, item.category);
});
classifier.train();

// ì´ìŠˆ ìë™ ë¶„ë¥˜ ë° ì²˜ë¦¬
app.post('/webhook/issues', async (req, res) => {
  const { action, issue, repository } = req.body;
  
  if (action !== 'opened') {
    return res.status(200).send('OK');
  }
  
  try {
    // 1. ì´ìŠˆ ë‚´ìš© ë¶„ì„
    const category = classifier.classify(issue.title + ' ' + issue.body);
    const sentiment = analyzeSentiment(issue.body);
    const priority = calculatePriority(issue, category, sentiment);
    
    // 2. ë¼ë²¨ ì¶”ê°€
    const labels = [category];
    if (priority === 'high') labels.push('high-priority');
    if (sentiment < -0.5) labels.push('urgent');
    
    await octokit.issues.addLabels({
      owner: repository.owner.login,
      repo: repository.name,
      issue_number: issue.number,
      labels,
    });
    
    // 3. ìë™ í• ë‹¹
    const assignee = await findBestAssignee(repository, category);
    if (assignee) {
      await octokit.issues.addAssignees({
        owner: repository.owner.login,
        repo: repository.name,
        issue_number: issue.number,
        assignees: [assignee],
      });
    }
    
    // 4. í”„ë¡œì íŠ¸ ë³´ë“œì— ì¶”ê°€
    await addToProjectBoard(repository, issue, category);
    
    // 5. ìë™ ì‘ë‹µ
    const response = generateAutoResponse(category, issue);
    await octokit.issues.createComment({
      owner: repository.owner.login,
      repo: repository.name,
      issue_number: issue.number,
      body: response,
    });
    
    // 6. ê´€ë ¨ ì´ìŠˆ ì°¾ê¸°
    const relatedIssues = await findRelatedIssues(repository, issue);
    if (relatedIssues.length > 0) {
      await octokit.issues.createComment({
        owner: repository.owner.login,
        repo: repository.name,
        issue_number: issue.number,
        body: `ê´€ë ¨ ì´ìŠˆ: ${relatedIssues.map(i => `#${i.number}`).join(', ')}`,
      });
    }
    
    res.status(200).send('Processed');
  } catch (error) {
    console.error('Error processing issue:', error);
    res.status(500).send('Error');
  }
});

// ìµœì ì˜ ë‹´ë‹¹ì ì°¾ê¸°
async function findBestAssignee(repository, category) {
  // ìµœê·¼ í™œë™ ê¸°ë¡ ì¡°íšŒ
  const { data: events } = await octokit.activity.listRepoEvents({
    owner: repository.owner.login,
    repo: repository.name,
    per_page: 100,
  });
  
  // ì¹´í…Œê³ ë¦¬ë³„ ì „ë¬¸ê°€ ì°¾ê¸°
  const experts = {};
  
  for (const event of events) {
    if (event.type === 'PullRequestEvent' && event.payload.pull_request.merged) {
      const files = await octokit.pulls.listFiles({
        owner: repository.owner.login,
        repo: repository.name,
        pull_number: event.payload.pull_request.number,
      });
      
      // íŒŒì¼ íŒ¨í„´ ê¸°ë°˜ ì „ë¬¸ì„± íŒë‹¨
      const expertise = determineExpertise(files.data);
      if (expertise === category) {
        experts[event.actor.login] = (experts[event.actor.login] || 0) + 1;
      }
    }
  }
  
  // ê°€ì¥ í™œë°œí•œ ì „ë¬¸ê°€ ì„ íƒ
  const sortedExperts = Object.entries(experts)
    .sort(([, a], [, b]) => b - a)
    .map(([login]) => login);
  
  return sortedExperts[0] || null;
}

// ìë™ ì‘ë‹µ ìƒì„±
function generateAutoResponse(category, issue) {
  const templates = {
    bug: `ì•ˆë…•í•˜ì„¸ìš” @${issue.user.login}ë‹˜,

ë²„ê·¸ ë¦¬í¬íŠ¸ë¥¼ ì œì¶œí•´ ì£¼ì…”ì„œ ê°ì‚¬í•©ë‹ˆë‹¤. ì €í¬ íŒ€ì—ì„œ í™•ì¸ í›„ ë¹ ë¥´ê²Œ ëŒ€ì‘í•˜ê² ìŠµë‹ˆë‹¤.

ì¶”ê°€ë¡œ ë‹¤ìŒ ì •ë³´ë¥¼ ì œê³µí•´ ì£¼ì‹œë©´ ë” ë¹ ë¥¸ í•´ê²°ì— ë„ì›€ì´ ë©ë‹ˆë‹¤:
- ìš´ì˜ì²´ì œ ë° ë²„ì „
- ë¸Œë¼ìš°ì € ì •ë³´ (ì›¹ ì• í”Œë¦¬ì¼€ì´ì…˜ì¸ ê²½ìš°)
- ì—ëŸ¬ ë©”ì‹œì§€ë‚˜ ìŠ¤í¬ë¦°ìƒ·
- ì¬í˜„ ê°€ëŠ¥í•œ ìµœì†Œ ì½”ë“œ ì˜ˆì œ`,
    
    enhancement: `ì•ˆë…•í•˜ì„¸ìš” @${issue.user.login}ë‹˜,

ì¢‹ì€ ì œì•ˆ ê°ì‚¬í•©ë‹ˆë‹¤! ì €í¬ íŒ€ì—ì„œ ê²€í†  í›„ êµ¬í˜„ ê°€ëŠ¥ì„±ì„ í‰ê°€í•˜ê² ìŠµë‹ˆë‹¤.

ë‹¤ìŒ ì •ë³´ë¥¼ ì¶”ê°€ë¡œ ì œê³µí•´ ì£¼ì‹œë©´ ë„ì›€ì´ ë©ë‹ˆë‹¤:
- ì œì•ˆí•˜ì‹  ê¸°ëŠ¥ì˜ êµ¬ì²´ì ì¸ ì‚¬ìš© ì‚¬ë¡€
- ì˜ˆìƒë˜ëŠ” ì‚¬ìš©ì ê²½í—˜
- ì°¸ê³ í•  ë§Œí•œ ë‹¤ë¥¸ í”„ë¡œì íŠ¸ë‚˜ êµ¬í˜„ ì‚¬ë¡€`,
    
    documentation: `ì•ˆë…•í•˜ì„¸ìš” @${issue.user.login}ë‹˜,

ë¬¸ì„œ ê°œì„  ì œì•ˆ ê°ì‚¬í•©ë‹ˆë‹¤. ë¬¸ì„œíŒ€ì—ì„œ ê²€í†  í›„ ì—…ë°ì´íŠ¸í•˜ê² ìŠµë‹ˆë‹¤.

í˜¹ì‹œ ì§ì ‘ ê¸°ì—¬í•˜ê³  ì‹¶ìœ¼ì‹œë‹¤ë©´ PRì„ ì œì¶œí•´ ì£¼ì…”ë„ ì¢‹ìŠµë‹ˆë‹¤!`,
  };
  
  return templates[category] || `ê°ì‚¬í•©ë‹ˆë‹¤. ê³§ ê²€í† í•˜ê² ìŠµë‹ˆë‹¤.`;
}
```

### CI/CD ìƒíƒœ ëŒ€ì‹œë³´ë“œ

```javascript
// ci-dashboard.js
const express = require('express');
const { graphql } = require('@octokit/graphql');

const app = express();

// ì‹¤ì‹œê°„ CI/CD ìƒíƒœ ëª¨ë‹ˆí„°ë§
app.get('/api/ci-status/:owner/:repo', async (req, res) => {
  const { owner, repo } = req.params;
  
  const query = `
    query GetCIStatus($owner: String!, $repo: String!) {
      repository(owner: $owner, name: $repo) {
        defaultBranchRef {
          name
          target {
            ... on Commit {
              statusCheckRollup {
                state
                contexts(first: 100) {
                  nodes {
                    __typename
                    ... on CheckRun {
                      name
                      status
                      conclusion
                      startedAt
                      completedAt
                      detailsUrl
                    }
                    ... on StatusContext {
                      state
                      description
                      context
                      targetUrl
                    }
                  }
                }
              }
            }
          }
        }
        pullRequests(first: 10, states: OPEN, orderBy: {field: UPDATED_AT, direction: DESC}) {
          nodes {
            number
            title
            author {
              login
            }
            commits(last: 1) {
              nodes {
                commit {
                  statusCheckRollup {
                    state
                  }
                }
              }
            }
          }
        }
      }
    }
  `;
  
  try {
    const result = await graphql(query, {
      owner,
      repo,
      headers: {
        authorization: `token ${process.env.GITHUB_TOKEN}`,
      },
    });
    
    const status = {
      mainBranch: {
        name: result.repository.defaultBranchRef.name,
        status: result.repository.defaultBranchRef.target.statusCheckRollup?.state || 'UNKNOWN',
        checks: result.repository.defaultBranchRef.target.statusCheckRollup?.contexts.nodes || [],
      },
      pullRequests: result.repository.pullRequests.nodes.map(pr => ({
        number: pr.number,
        title: pr.title,
        author: pr.author.login,
        status: pr.commits.nodes[0]?.commit.statusCheckRollup?.state || 'UNKNOWN',
      })),
    };
    
    res.json(status);
  } catch (error) {
    res.status(500).json({ error: error.message });
  }
});

// Webhookìœ¼ë¡œ ì‹¤ì‹œê°„ ì—…ë°ì´íŠ¸
app.post('/webhook/status', async (req, res) => {
  const { state, sha, repository, context, target_url } = req.body;
  
  // WebSocketìœ¼ë¡œ í´ë¼ì´ì–¸íŠ¸ì— ì‹¤ì‹œê°„ ì „ì†¡
  io.emit('ci-status-update', {
    repository: repository.full_name,
    commit: sha,
    context,
    state,
    url: target_url,
    timestamp: new Date().toISOString(),
  });
  
  // ì‹¤íŒ¨ ì‹œ ì•Œë¦¼
  if (state === 'failure') {
    await sendFailureNotification({
      repository: repository.full_name,
      context,
      sha,
      url: target_url,
    });
  }
  
  res.status(200).send('OK');
});
```

## 5. ë³´ì•ˆ ê³ ë ¤ì‚¬í•­

### Webhook ë³´ì•ˆ ê°•í™”

```javascript
// webhook-security.js
const crypto = require('crypto');
const ipRangeCheck = require('ip-range-check');

// GitHubì˜ IP ë²”ìœ„
const GITHUB_IP_RANGES = [
  '192.30.252.0/22',
  '185.199.108.0/22',
  '140.82.112.0/20',
  '143.55.64.0/20',
];

// IP í™”ì´íŠ¸ë¦¬ìŠ¤íŠ¸ ê²€ì¦
function verifyGitHubIP(req) {
  const clientIP = req.headers['x-forwarded-for'] || req.connection.remoteAddress;
  return ipRangeCheck(clientIP, GITHUB_IP_RANGES);
}

// ì„œëª… ê²€ì¦ (íƒ€ì´ë° ê³µê²© ë°©ì§€)
function verifySignature(payload, signature, secret) {
  if (!signature) return false;
  
  const [algo, hash] = signature.split('=');
  if (algo !== 'sha256') return false;
  
  const expectedHash = crypto
    .createHmac('sha256', secret)
    .update(payload)
    .digest('hex');
  
  return crypto.timingSafeEqual(
    Buffer.from(hash),
    Buffer.from(expectedHash)
  );
}

// ì¬ì „ì†¡ ê³µê²© ë°©ì§€
const processedDeliveries = new Set();

function preventReplay(deliveryId) {
  if (processedDeliveries.has(deliveryId)) {
    return false;
  }
  
  processedDeliveries.add(deliveryId);
  
  // 1ì‹œê°„ í›„ ì œê±°
  setTimeout(() => {
    processedDeliveries.delete(deliveryId);
  }, 60 * 60 * 1000);
  
  return true;
}

// ë³´ì•ˆ ë¯¸ë“¤ì›¨ì–´
function webhookSecurity(secret) {
  return (req, res, next) => {
    // 1. IP ê²€ì¦
    if (!verifyGitHubIP(req)) {
      return res.status(403).send('Forbidden: Invalid IP');
    }
    
    // 2. ì„œëª… ê²€ì¦
    const signature = req.headers['x-hub-signature-256'];
    if (!verifySignature(req.rawBody, signature, secret)) {
      return res.status(401).send('Unauthorized: Invalid signature');
    }
    
    // 3. ì¬ì „ì†¡ ê³µê²© ë°©ì§€
    const deliveryId = req.headers['x-github-delivery'];
    if (!preventReplay(deliveryId)) {
      return res.status(409).send('Conflict: Duplicate delivery');
    }
    
    // 4. ì´ë²¤íŠ¸ íƒ€ì… ê²€ì¦
    const event = req.headers['x-github-event'];
    const allowedEvents = ['push', 'pull_request', 'issues', 'release'];
    if (!allowedEvents.includes(event)) {
      return res.status(400).send('Bad Request: Unsupported event');
    }
    
    next();
  };
}

// ì‚¬ìš© ì˜ˆì œ
app.post('/webhook',
  express.raw({ type: 'application/json' }),
  webhookSecurity(process.env.WEBHOOK_SECRET),
  async (req, res) => {
    // ì•ˆì „í•˜ê²Œ ì²˜ë¦¬
    const payload = JSON.parse(req.body);
    // ...
  }
);
```

### API í† í° ê´€ë¦¬

```javascript
// token-manager.js
const crypto = require('crypto');
const jwt = require('jsonwebtoken');

class TokenManager {
  constructor() {
    this.tokens = new Map();
    this.rotationInterval = 30 * 24 * 60 * 60 * 1000; // 30ì¼
  }
  
  // ì•± ì„¤ì¹˜ í† í° ìƒì„± (GitHub App)
  async generateInstallationToken(installationId) {
    const appId = process.env.GITHUB_APP_ID;
    const privateKey = process.env.GITHUB_APP_PRIVATE_KEY;
    
    // JWT ìƒì„±
    const now = Math.floor(Date.now() / 1000);
    const payload = {
      iat: now - 60,
      exp: now + 600,
      iss: appId,
    };
    
    const jwtToken = jwt.sign(payload, privateKey, {
      algorithm: 'RS256',
    });
    
    // ì„¤ì¹˜ í† í° ìš”ì²­
    const response = await fetch(
      `https://api.github.com/app/installations/${installationId}/access_tokens`,
      {
        method: 'POST',
        headers: {
          'Authorization': `Bearer ${jwtToken}`,
          'Accept': 'application/vnd.github.v3+json',
        },
      }
    );
    
    const data = await response.json();
    
    // í† í° ì €ì¥ ë° ë§Œë£Œ ì¶”ì 
    this.tokens.set(installationId, {
      token: data.token,
      expiresAt: new Date(data.expires_at),
    });
    
    return data.token;
  }
  
  // í† í° ê°±ì‹ 
  async refreshToken(installationId) {
    const tokenData = this.tokens.get(installationId);
    if (!tokenData) {
      return this.generateInstallationToken(installationId);
    }
    
    const now = new Date();
    const expiresIn = tokenData.expiresAt - now;
    
    // 5ë¶„ ì´ë‚´ ë§Œë£Œ ì‹œ ê°±ì‹ 
    if (expiresIn < 5 * 60 * 1000) {
      return this.generateInstallationToken(installationId);
    }
    
    return tokenData.token;
  }
  
  // Fine-grained PAT ê²€ì¦
  async validateToken(token) {
    try {
      const response = await fetch('https://api.github.com/user', {
        headers: {
          'Authorization': `token ${token}`,
        },
      });
      
      if (!response.ok) {
        return { valid: false, reason: 'Invalid token' };
      }
      
      // ê¶Œí•œ í™•ì¸
      const scopes = response.headers.get('x-oauth-scopes');
      const rateLimit = {
        limit: response.headers.get('x-ratelimit-limit'),
        remaining: response.headers.get('x-ratelimit-remaining'),
        reset: new Date(response.headers.get('x-ratelimit-reset') * 1000),
      };
      
      return {
        valid: true,
        scopes: scopes ? scopes.split(', ') : [],
        rateLimit,
      };
    } catch (error) {
      return { valid: false, reason: error.message };
    }
  }
}

module.exports = new TokenManager();
```

## 6. ì‹¤ì „ í†µí•© ì˜ˆì œ

### PR ìë™ ë¦¬ë·° ë´‡

```javascript
// pr-review-bot.js
const { Octokit } = require('@octokit/rest');
const { minimatch } = require('minimatch');

class PRReviewBot {
  constructor(token) {
    this.octokit = new Octokit({ auth: token });
    this.rules = this.loadRules();
  }
  
  loadRules() {
    return {
      security: {
        patterns: [
          /api[_-]?key/i,
          /secret/i,
          /password/i,
          /token/i,
        ],
        message: 'ğŸ” ë³´ì•ˆ ê²½ê³ : ë¯¼ê°í•œ ì •ë³´ê°€ í¬í•¨ë˜ì–´ ìˆì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.',
      },
      performance: {
        patterns: [
          /SELECT \* FROM/i,
          /\.forEach\(.+\.forEach/,
          /async.+await.+for/,
        ],
        message: 'âš¡ ì„±ëŠ¥: ì´ íŒ¨í„´ì€ ì„±ëŠ¥ ë¬¸ì œë¥¼ ì¼ìœ¼í‚¬ ìˆ˜ ìˆìŠµë‹ˆë‹¤.',
      },
      codeQuality: {
        maxFileSize: 500,
        maxFunctionLength: 50,
        maxComplexity: 10,
      },
    };
  }
  
  async reviewPR(owner, repo, prNumber) {
    // PR ì •ë³´ ê°€ì ¸ì˜¤ê¸°
    const { data: pr } = await this.octokit.pulls.get({
      owner,
      repo,
      pull_number: prNumber,
    });
    
    // ë³€ê²½ëœ íŒŒì¼ ê°€ì ¸ì˜¤ê¸°
    const { data: files } = await this.octokit.pulls.listFiles({
      owner,
      repo,
      pull_number: prNumber,
    });
    
    const comments = [];
    const problems = [];
    
    for (const file of files) {
      // íŒŒì¼ í¬ê¸° ì²´í¬
      if (file.additions > this.rules.codeQuality.maxFileSize) {
        problems.push({
          path: file.filename,
          message: `íŒŒì¼ì´ ë„ˆë¬´ í½ë‹ˆë‹¤ (${file.additions}ì¤„). ë¶„í• ì„ ê³ ë ¤í•´ì£¼ì„¸ìš”.`,
        });
      }
      
      // íŒŒì¼ ë‚´ìš© ë¶„ì„
      if (file.patch) {
        const issues = await this.analyzeFile(file);
        comments.push(...issues);
      }
    }
    
    // ë¦¬ë·° ì œì¶œ
    if (comments.length > 0 || problems.length > 0) {
      await this.submitReview(owner, repo, prNumber, pr.head.sha, comments, problems);
    }
    
    // ìë™ ë¼ë²¨ ì¶”ê°€
    await this.addLabels(owner, repo, prNumber, files);
    
    return { comments: comments.length, problems: problems.length };
  }
  
  async analyzeFile(file) {
    const comments = [];
    const lines = file.patch.split('\n');
    
    lines.forEach((line, index) => {
      // ì¶”ê°€ëœ ë¼ì¸ë§Œ ê²€ì‚¬
      if (!line.startsWith('+')) return;
      
      // ë³´ì•ˆ íŒ¨í„´ ê²€ì‚¬
      for (const pattern of this.rules.security.patterns) {
        if (pattern.test(line)) {
          comments.push({
            path: file.filename,
            line: this.getLineNumber(file.patch, index),
            body: this.rules.security.message,
          });
        }
      }
      
      // ì„±ëŠ¥ íŒ¨í„´ ê²€ì‚¬
      for (const pattern of this.rules.performance.patterns) {
        if (pattern.test(line)) {
          comments.push({
            path: file.filename,
            line: this.getLineNumber(file.patch, index),
            body: this.rules.performance.message,
          });
        }
      }
      
      // TODO ì£¼ì„ ì°¾ê¸°
      if (/TODO|FIXME|HACK/i.test(line)) {
        comments.push({
          path: file.filename,
          line: this.getLineNumber(file.patch, index),
          body: 'ğŸ“ TODO ì£¼ì„ì´ ë°œê²¬ë˜ì—ˆìŠµë‹ˆë‹¤. ì´ìŠˆë¡œ ë“±ë¡í•˜ëŠ” ê²ƒì„ ê³ ë ¤í•´ì£¼ì„¸ìš”.',
        });
      }
    });
    
    return comments;
  }
  
  getLineNumber(patch, patchLineIndex) {
    const lines = patch.split('\n');
    let lineNumber = 0;
    
    for (let i = 0; i <= patchLineIndex; i++) {
      const line = lines[i];
      if (line.startsWith('@@')) {
        const match = line.match(/@@ -\d+,?\d* \+(\d+)/);
        if (match) {
          lineNumber = parseInt(match[1]) - 1;
        }
      } else if (!line.startsWith('-')) {
        lineNumber++;
      }
    }
    
    return lineNumber;
  }
  
  async submitReview(owner, repo, prNumber, commitSha, comments, problems) {
    const body = problems.length > 0
      ? `## ì „ì²´ì ì¸ í”¼ë“œë°±\n\n${problems.map(p => `- **${p.path}**: ${p.message}`).join('\n')}`
      : '';
    
    await this.octokit.pulls.createReview({
      owner,
      repo,
      pull_number: prNumber,
      commit_id: commitSha,
      body,
      event: 'COMMENT',
      comments: comments.map(c => ({
        path: c.path,
        line: c.line,
        body: c.body,
      })),
    });
  }
  
  async addLabels(owner, repo, prNumber, files) {
    const labels = new Set();
    
    files.forEach(file => {
      if (file.filename.includes('test')) {
        labels.add('tests');
      }
      if (file.filename.endsWith('.md')) {
        labels.add('documentation');
      }
      if (file.filename.startsWith('src/')) {
        labels.add('source-code');
      }
      if (file.filename.includes('package.json')) {
        labels.add('dependencies');
      }
    });
    
    if (labels.size > 0) {
      await this.octokit.issues.addLabels({
        owner,
        repo,
        issue_number: prNumber,
        labels: Array.from(labels),
      });
    }
  }
}

// Webhook í•¸ë“¤ëŸ¬
app.post('/webhook/pr', async (req, res) => {
  const { action, pull_request, repository } = req.body;
  
  if (action === 'opened' || action === 'synchronize') {
    const bot = new PRReviewBot(process.env.GITHUB_TOKEN);
    
    try {
      const result = await bot.reviewPR(
        repository.owner.login,
        repository.name,
        pull_request.number
      );
      
      console.log(`Reviewed PR #${pull_request.number}: ${result.comments} comments, ${result.problems} problems`);
      res.status(200).send('Review completed');
    } catch (error) {
      console.error('Review failed:', error);
      res.status(500).send('Review failed');
    }
  } else {
    res.status(200).send('Ignored');
  }
});
```

## 2025ë…„ ìµœì‹  API ê¸°ëŠ¥

### GitHub API ë²„ì „ë³„ ë¹„êµ

| ë²„ì „ | REST API v3 | GraphQL v4 | REST API v4 (2025) |
|------|-------------|------------|-------------------|
| **í”„ë¡œí† ì½œ** | REST | GraphQL | REST + GraphQL |
| **ë°ì´í„° í˜ì¹­** | ê³¼ë‹¤ í˜ì¹­ | í•„ìš”í•œ ê²ƒë§Œ | í•˜ì´ë¸Œë¦¬ë“œ |
| **Rate Limit** | 5,000/ì‹œê°„ | 5,000 í¬ì¸íŠ¸/ì‹œê°„ | 10,000/ì‹œê°„ |
| **ì‹¤ì‹œê°„ ê¸°ëŠ¥** | ì—†ìŒ | Subscription | WebSocket ì§€ì› |
| **ìºì‹±** | HTTP ìºì‹± | ì œí•œì  | ìŠ¤ë§ˆíŠ¸ ìºì‹± |

### í†µí•© ìë™í™” ì•„í‚¤í…ì²˜

```mermaid
graph TB
    A[GitHub] --> B[Webhook Event]
    B --> C[Event Router]
    
    C --> D[CI/CD Pipeline]
    C --> E[Issue Automation]
    C --> F[Code Review Bot]
    C --> G[Notification Service]
    
    D --> H[Deploy]
    E --> I[Jira Sync]
    F --> J[AI Analysis]
    G --> K[Slack/Teams]
```

## ë§ˆë¬´ë¦¬

GitHub Webhooksì™€ APIëŠ” ê°•ë ¥í•œ ìë™í™”ì™€ í†µí•©ì„ ê°€ëŠ¥í•˜ê²Œ í•˜ëŠ” í•µì‹¬ ë„êµ¬ì…ë‹ˆë‹¤.

### í•µì‹¬ í¬ì¸íŠ¸ ì •ë¦¬

| ì˜ì—­ | ì£¼ìš” ë‚´ìš© | íš¨ê³¼ |
|------|-----------|------|
| **ì‹¤ì‹œê°„ ì²˜ë¦¬** | Webhooks ì´ë²¤íŠ¸ ê¸°ë°˜ ìë™í™” | ì¦‰ê°ì ì¸ ëŒ€ì‘ |
| **ë°ì´í„° ì ‘ê·¼** | REST/GraphQL API í™œìš© | ìœ ì—°í•œ ë°ì´í„° ì¡°ì‘ |
| **ë³´ì•ˆ** | ì„œëª… ê²€ì¦, í† í° ê´€ë¦¬ | ì•ˆì „í•œ í†µì‹  |
| **í™•ì¥ì„±** | Rate Limit ê´€ë¦¬, ë³‘ë ¬ ì²˜ë¦¬ | ëŒ€ê·œëª¨ ìš´ì˜ ê°€ëŠ¥ |
| **í†µí•©** | ë‹¤ì–‘í•œ ì„œë¹„ìŠ¤ ì—°ë™ | ì›Œí¬í”Œë¡œìš° ìµœì í™” |

ì´ëŸ¬í•œ ë„êµ¬ë“¤ì„ í™œìš©í•˜ì—¬ ê°œë°œ ì›Œí¬í”Œë¡œìš°ë¥¼ ìë™í™”í•˜ê³ , ìƒì‚°ì„±ì„ í¬ê²Œ í–¥ìƒì‹œí‚¬ ìˆ˜ ìˆìŠµë‹ˆë‹¤.

ë‹¤ìŒ í¸ì—ì„œëŠ” GitHub Apps ê°œë°œì— ëŒ€í•´ ìì„¸íˆ ì•Œì•„ë³´ê² ìŠµë‹ˆë‹¤.

## ì‹œë¦¬ì¦ˆ ëª©ì°¨
1. [GitHub ì‹œì‘í•˜ê¸°](/posts/github-series-01-getting-started/)
2. [Repository ê¸°ì´ˆ](/posts/github-series-02-repository-basics/)
3. [Git ê¸°ë³¸ ëª…ë ¹ì–´](/posts/github-series-03-git-basic-commands/)
4. [Branchì™€ Merge](/posts/github-series-04-branch-and-merge/)
5. [Forkì™€ Pull Request](/posts/github-series-05-fork-and-pull-request/)
6. [Issues í™œìš©ë²•](/posts/github-series-06-issues-management/)
7. [Projectsë¡œ í”„ë¡œì íŠ¸ ê´€ë¦¬](/posts/github-series-07-projects-kanban/)
8. [Code Review ì˜í•˜ê¸°](/posts/github-series-08-code-review/)
9. [GitHub Discussions](/posts/github-series-09-discussions/)
10. [Team í˜‘ì—… ì„¤ì •](/posts/github-series-10-team-collaboration/)
11. [GitHub Actions ì…ë¬¸](/posts/github-series-11-github-actions-intro/)
12. [Actions ê³ ê¸‰ í™œìš©](/posts/github-series-12-actions-advanced/)
13. **Webhooksì™€ API** (í˜„ì¬ ê¸€)
14. GitHub Apps ê°œë°œ (ì˜ˆì •)

---

*ì§ˆë¬¸ì´ë‚˜ í”¼ë“œë°±ì´ ìˆìœ¼ì‹œë‹¤ë©´ ëŒ“ê¸€ë¡œ ë‚¨ê²¨ì£¼ì„¸ìš”!*